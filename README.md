# 課題３ テキストクラスタリング問題

## データセット作成
- csvの文章部分をMeCabで単語ごとに変換して名詞のみ抽出（文章のトピックに関しては名詞がもっともよく表現していると考えるため）
- tfidfモデルにより語彙次元のベクトルにデータを変換
- 今のままでは次元が高すぎる（のちの主成分分析を行った際に寄与度が大きく損なわれてしまう）ため，トピックモデルによって次元削減（LSIを選択．）
- LSIのトピック数は，100を設定．のちに主成分分析で次元削減を行うことを見据えて，多少大きめに設定．


## アルゴリズムとクラスター数
- 階層型アルゴリズムを実施： データの階層構造として，クラスタ数の変化に対してクラスタ間類似度がもっとも大きく変化するような点に注目して，クラスタ数を決定する．
- 上記で求めたクラスタ数を用いて，k-meansを実施．

## テスト結果
キーワードランキング：付属のjsonファイルに記載．
- クラスタ1:報道，メディア
- クラスタ2: 宇宙，現代社会
- クラスタ3:特になし，ノイズ
- クラスタ4:マーケティング

クラスタ1,クラスタ４は比較的一貫性があるキーワードが獲得された．  
クラスタ2に関しては，様々なジャンルの言葉が混在している模様であり，さらにクラスタリングを改善する余地があるように感じられる．  
クラスタ3はMeCabの解析過程に誤りがあったことが起因してノイズとなるキーワードが獲得されていると考えられる．この問題に関しては，MeCab辞書をより高精度化（mecab-ipadic-NEologdの実装）することにより改善が見込める．
## コード実行手順
```
python work3.py [Sample.csvのpath] [トピック数]
```
## その他
